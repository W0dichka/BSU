Задание 07. Методы отбора признаков
Корреляционные методы отбора признаков
1. Задание 1: Работа с корреляционной матрицей.
    Используйте набор данных "Iris" из sklearn.datasets. Вычислите корреляционную матрицу числовых признаков. Затем визуализируйте эту матрицу с помощью heatmap в библиотеке seaborn.
2. Задание 2: Исключение мультиколлинеарных признаков.
    Используйте набор данных "Wine" из sklearn.datasets. Вычислите корреляционную матрицу, а затем найдите и исключите признаки, у которых корреляция друг с другом превышает заданный порог.
3. Задание 3: Выбор наиболее значимых признаков.
    Используйте набор данных "Boston Housing" из sklearn.datasets. Вычислите коэффициенты корреляции между каждым признаком и целевой переменной, затем выберите n признаков с наибольшим абсолютным значением коэффициента.
4. Задание 4: Применение Ранговой корреляции Спирмена.
    Используйте любой набор данных, имеющий порядковые признаки. Примените корреляцию Спирмена для выбора наиболее значимых признаков.
5. Задание 5: Сравнение методов отбора признаков.
    Используйте один и тот же набор данных для применения различных методов отбора признаков, включая корреляционные методы, и сравните результаты.
6. Задание 6: Исследование влияния предобработки данных на результаты корреляционного анализа.
    Примените различные методы предобработки (например, нормализацию, стандартизацию, логарифмирование) к данным перед вычислением корреляции и сравните полученные результаты.
Каждое задание должно включать в себя следующие шаги: загрузка и предварительная обработка данных, применение метода отбора признаков, и, при необходимости, обучение модели на выбранных признаках и оценка производительности модели.
Здесь можно найти больше датасетов для этих задач:
UCI Machine Learning Repository: [ссылка](http://archive.ics.uci.edu/ml/index.php)
- Kaggle Datasets: [ссылка](https://www.kaggle.com/datasets)
- Google's Dataset Search: [ссылка](https://datasetsearch.research.google.com/)
Методы-обертки
1. Задание 1: Рекурсивное исключение признаков (RFE).
    Используйте набор данных "Iris" из sklearn.datasets. Примените метод RFE с использованием модели логистической регрессии. Укажите количество признаков для выбора и сравните производительность модели с и без этих признаков.
2. Задание 2: Sequential Feature Selector.
    Используйте набор данных "Boston Housing" из sklearn.datasets. Используйте Sequential Feature Selector для выбора признаков с использованием модели Random Forest. Визуализируйте "важность" признаков.
3. Задание 3: Использование метода-обертки при кросс-валидации.
    Используйте любой набор данных на ваше усмотрение. Выберите модель машинного обучения и метод-обертку для отбора признаков. Примените кросс-валидацию, чтобы оценить эффективность этого подхода.
4. Задание 4: Сравнение методов-оберток.
    Используйте один и тот же набор данных для применения различных методов-оберток для отбора признаков, например, RFE и Sequential Feature Selector, и сравните полученные результаты.
5. Задание 5: Анализ предсказательной способности признаков.
    Используйте набор данных "Wine" из sklearn.datasets. Выберите модель машинного обучения и метод-обертку для отбора признаков и исследуйте, как влияет отбор признаков на предсказательную способность модели.
Каждое задание должно включать в себя следующие шаги: загрузка и предварительная обработка данных, применение метода отбора признаков, обучение модели на выбранных признаках и оценка производительности модели.
Если вы хотите найти больше данных для этих задач, вы можете выйти на такие источники:
- UCI Machine Learning Repository: [ссылка](http://archive.ics.uci.edu/ml/index.php)
- Kaggle Datasets: [ссылка](https://www.kaggle.com/datasets)
- Google's Dataset Search: [ссылка](https://datasetsearch.research.google.com/)